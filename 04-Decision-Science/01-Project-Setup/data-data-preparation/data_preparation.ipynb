{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"magic commands\" to enable autoreload of your imported packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to load all 9 `.csv` files into 9 `pandas.DataFrame`s in a single dict named `data` where:\n",
    "- each **key** is the **cleaned name** of the csv file\n",
    "- each **value** is the **DataFrame** created from the csv\n",
    "\n",
    "```python\n",
    "data = { \n",
    "    'sellers': DataFrame1,\n",
    "    'orders': DataFrame2,\n",
    "    ...\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create the variable `csv_path`, which stores the path to your `\"csv\" folder` as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When calling `pd.read_csv(csv_path)`, `csv_path` can be absolute or relative:\n",
    "    - A **`relative path`** can start with `.` or `..`, it is always computed with respect to your current working directory \n",
    "        - *Reminder: you can use `!pwd` in your notebook or `pwd` in your terminal to know where you are located*\n",
    "    - An **`absolute path`** starts with `/` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/andreza/code/andrezaumbelino/04-Decision-Science/01-Project-Setup/data-data-preparation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your current working directory using `os.getcwd()` below\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ `getcwd` a.k.a `get current working directory` refers to the absolute path _from which this notebook is being executed_\n",
    "\n",
    "Create a relative `csv_path` from your current folder to the csv folder.\n",
    "\n",
    "Try to use [`os.path.join`](https://docs.python.org/3/library/os.path.html), which replaces both:\n",
    "* Linux/MacOS syntax (e.g. `../folder_name`) \n",
    "* and Windows syntax (e.g. `..\\\\folder_name`) \n",
    "\n",
    "and is therefore more robust!\n",
    "\n",
    "Have a look at the image below to see how you can get from your current location to the csv folder.\n",
    "<img alt=\"Folder structure of olist with relative path\" src=\"https://wagon-public-datasets.s3.amazonaws.com/04-Decision-Science/01-Project-Setup/folders-olist-data-relative.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "csv_path = os.path.join(\"..\", \"data-context-and-setup\", \"data\", \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_zip_code_prefix</th>\n",
       "      <th>seller_city</th>\n",
       "      <th>seller_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3442f8959a84dea7ee197c632cb2df15</td>\n",
       "      <td>13023</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>\n",
       "      <td>13844</td>\n",
       "      <td>mogi guacu</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>\n",
       "      <td>20031</td>\n",
       "      <td>rio de janeiro</td>\n",
       "      <td>RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>\n",
       "      <td>4195</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>\n",
       "      <td>12914</td>\n",
       "      <td>braganca paulista</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          seller_id  seller_zip_code_prefix  \\\n",
       "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
       "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
       "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
       "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
       "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
       "\n",
       "         seller_city seller_state  \n",
       "0           campinas           SP  \n",
       "1         mogi guacu           SP  \n",
       "2     rio de janeiro           RJ  \n",
       "3          sao paulo           SP  \n",
       "4  braganca paulista           SP  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code below\n",
    "import pandas as pd\n",
    "pd.read_csv(os.path.join(csv_path, 'olist_sellers_dataset.csv')).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create the list `file_names` containing all csv file names in the csv directory\n",
    "\n",
    "- It should look like this `file_names = ['olist_sellers_dataset.csv', ....]`\n",
    "- You can use `os.listdir()`\n",
    "- Make sure it only lists csv files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['olist_products_dataset.csv',\n",
       " 'product_category_name_translation.csv',\n",
       " 'olist_geolocation_dataset.csv',\n",
       " 'olist_order_reviews_dataset.csv',\n",
       " 'olist_sellers_dataset.csv',\n",
       " 'olist_order_payments_dataset.csv',\n",
       " 'olist_customers_dataset.csv',\n",
       " 'olist_order_items_dataset.csv',\n",
       " 'olist_orders_dataset.csv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = []\n",
    "for f in os.listdir(csv_path):\n",
    "        if f.endswith(\".csv\"):\n",
    "            file_names.append(f)\n",
    "\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Create the list of dict key `key_names` \n",
    "Starting from file_names and:\n",
    "- Removing its suffix \".csv\" when it exists\n",
    "- Removing its suffix \"_dataset.csv\" when it exists\n",
    "- Removing its prefix \"olist_\" when it exists\n",
    "\n",
    "<details>\n",
    "    <summary>- Hint - </summary>\n",
    "\n",
    "- `.replace()`\n",
    "    \n",
    "- `str` ings are iterables you can slice with [ ]\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['products',\n",
       " 'product_category_name_translation',\n",
       " 'geolocation',\n",
       " 'order_reviews',\n",
       " 'sellers',\n",
       " 'order_payments',\n",
       " 'customers',\n",
       " 'order_items',\n",
       " 'orders']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_names = []\n",
    "\n",
    "for file in file_names:\n",
    "    name = file.replace(\"_dataset.csv\", \"\")  # Remover sufixo \"_dataset.csv\"\n",
    "    name = name.replace(\".csv\", \"\")  # Remover sufixo \".csv\" (caso exista)\n",
    "    name = name.replace(\"olist_\", \"\")  # Remover prefixo \"olist_\"\n",
    "    key_names.append(name)\n",
    "key_names\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Construct the dictionary `data`\n",
    "\n",
    "```python\n",
    "data = {\n",
    "    'sellers': DataFrame1,\n",
    "    'orders': DataFrame2,\n",
    "    'order_items': DataFrame3,\n",
    "    ...\n",
    "    }\n",
    "```\n",
    "Where `DataFrame1`, `DataFrame2`, ... should be actual `pandas.DataFrame`s! Not strings containing the file path to the csv files\n",
    "\n",
    "<details>\n",
    "    <summary>▸ Hint</summary>\n",
    "\n",
    "The `zip()` method is very useful to iterate over two lists\n",
    "```python\n",
    "for (x, y) in zip(['a','b','c'], [1,2,3]):\n",
    "    print(x,y)\n",
    "\n",
    "# returns ('a', 1), ('b', 2), ('c', 3)\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geolocation_zip_code_prefix</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>geolocation_city</th>\n",
       "      <th>geolocation_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037</td>\n",
       "      <td>-23.545621</td>\n",
       "      <td>-46.639292</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546081</td>\n",
       "      <td>-46.644820</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1046</td>\n",
       "      <td>-23.546129</td>\n",
       "      <td>-46.642951</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1041</td>\n",
       "      <td>-23.544392</td>\n",
       "      <td>-46.639499</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1035</td>\n",
       "      <td>-23.541578</td>\n",
       "      <td>-46.641607</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000158</th>\n",
       "      <td>99950</td>\n",
       "      <td>-28.068639</td>\n",
       "      <td>-52.010705</td>\n",
       "      <td>tapejara</td>\n",
       "      <td>RS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000159</th>\n",
       "      <td>99900</td>\n",
       "      <td>-27.877125</td>\n",
       "      <td>-52.224882</td>\n",
       "      <td>getulio vargas</td>\n",
       "      <td>RS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000160</th>\n",
       "      <td>99950</td>\n",
       "      <td>-28.071855</td>\n",
       "      <td>-52.014716</td>\n",
       "      <td>tapejara</td>\n",
       "      <td>RS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000161</th>\n",
       "      <td>99980</td>\n",
       "      <td>-28.388932</td>\n",
       "      <td>-51.846871</td>\n",
       "      <td>david canabarro</td>\n",
       "      <td>RS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000162</th>\n",
       "      <td>99950</td>\n",
       "      <td>-28.070104</td>\n",
       "      <td>-52.018658</td>\n",
       "      <td>tapejara</td>\n",
       "      <td>RS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000163 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
       "0                               1037       -23.545621       -46.639292   \n",
       "1                               1046       -23.546081       -46.644820   \n",
       "2                               1046       -23.546129       -46.642951   \n",
       "3                               1041       -23.544392       -46.639499   \n",
       "4                               1035       -23.541578       -46.641607   \n",
       "...                              ...              ...              ...   \n",
       "1000158                        99950       -28.068639       -52.010705   \n",
       "1000159                        99900       -27.877125       -52.224882   \n",
       "1000160                        99950       -28.071855       -52.014716   \n",
       "1000161                        99980       -28.388932       -51.846871   \n",
       "1000162                        99950       -28.070104       -52.018658   \n",
       "\n",
       "        geolocation_city geolocation_state  \n",
       "0              sao paulo                SP  \n",
       "1              sao paulo                SP  \n",
       "2              sao paulo                SP  \n",
       "3              sao paulo                SP  \n",
       "4              sao paulo                SP  \n",
       "...                  ...               ...  \n",
       "1000158         tapejara                RS  \n",
       "1000159   getulio vargas                RS  \n",
       "1000160         tapejara                RS  \n",
       "1000161  david canabarro                RS  \n",
       "1000162         tapejara                RS  \n",
       "\n",
       "[1000163 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for name, file in zip(key_names, file_names):\n",
    "    data[name] = pd.read_csv(os.path.join(csv_path, file))\n",
    "data['geolocation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implement the method `get_data()` in `olist/data.py`\n",
    "\n",
    "Time to move our logic from the notebook into our `.py` files. This will allow us to easily load the data in the new notebooks we'll create througout this module. \n",
    "\n",
    "Go and open the `olist/data.py` file in the previous challenge's folder, and start moving the code you have written in this notebook to the `get_data()` method. Along the way you will need to make some changes (read further 👇 for some hints).\n",
    "\n",
    "It should return the dictionary `data` upon calling it as per below\n",
    "\n",
    "```python\n",
    "from olist.data import Olist\n",
    "Olist().get_data()\n",
    "```\n",
    "- Take time to understand what happens when `Olist().get_data()` is called\n",
    "- Your method `get_data()` needs to be callable from various places (e.g your Terminal, this notebook, another notebook located elsewhere, etc...)\n",
    "- You can't use a relative path this time as the current working directory `os.getcwd()` depends on where you run the code in the first place\n",
    "- You also can't use a _hardcoded_ absolute path, because that won't work on someone else's system.\n",
    "- So we will have to let Python create the path for us, starting from `__file__`, which will give us the absolute location of our `data.py` file. Once we know that, we can construct the path to our csv folder again. Explore the image below to see how that works.\n",
    "   <img alt=\"Folder structure of olist\" src=\"https://wagon-public-datasets.s3.amazonaws.com/04-Decision-Science/01-Project-Setup/folders-olist-data.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<olist.data.Olist at 0x7a5fb93a9810>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from olist.data import Olist\n",
    "Olist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0 -- /home/andreza/.pyenv/versions/3.10.6/envs/lewagon/bin/python\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/andreza/code/andrezaumbelino/04-Decision-Science/01-Project-Setup/data-data-preparation/tests\n",
      "plugins: typeguard-2.13.3, asyncio-0.19.0, anyio-3.6.2\n",
      "asyncio: mode=strict\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 4 items\n",
      "\n",
      "test_get_data.py::TestGetData::test_columns \u001b[32mPASSED\u001b[0m\u001b[32m                       [ 25%]\u001b[0m\n",
      "test_get_data.py::TestGetData::test_keys \u001b[32mPASSED\u001b[0m\u001b[32m                          [ 50%]\u001b[0m\n",
      "test_get_data.py::TestGetData::test_len \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 75%]\u001b[0m\n",
      "test_get_data.py::TestGetData::test_using_dunder_file \u001b[32mPASSED\u001b[0m\u001b[32m             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m4 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "💯 You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/get_data.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed get_data step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "from olist.data import Olist\n",
    "data = Olist().get_data()\n",
    "result = ChallengeResult('get_data',\n",
    "    keys_len=len(data),\n",
    "    keys=sorted(list(data.keys())),\n",
    "    columns=sorted(list(data['sellers'].columns)),\n",
    "    vars_used=Olist.get_data.__code__.co_names\n",
    "    )\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'belo horizonte'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from olist.data import Olist\n",
    "Olist().get_data()['sellers']['seller_city'][25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓This piece of code needs to work from anywhere on your machine, not only in this notebook.\n",
    "- Open a new terminal\n",
    "- Go to your home folder `cd`\n",
    "- Launch an `ipython` session\n",
    "- Test the two lines of code above 👆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏁 Congratulations !\n",
    "\n",
    "💾 Don't forget to commit & push: \n",
    "* this `data_preparation.ipynb` notebook\n",
    "* as well as `data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
